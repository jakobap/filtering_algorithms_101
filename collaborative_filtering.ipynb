{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the libraries\n",
    "import csv\n",
    "from math import sqrt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import math\n",
    "import numpy as np\n",
    "import heapq\n",
    "import random\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds the mock data set\n",
    "input_file = csv.DictReader(open(f\"{data_path}/DataSets/movieratings.csv\"))\n",
    "critics = {}\n",
    "for row in input_file:\n",
    "    key = row.pop('User')\n",
    "    if not key in critics:\n",
    "        critics[key] = {}\n",
    "        for item in row:\n",
    "            if row[item]!='':critics[key][item] = float(row[item])\n",
    "                \n",
    "#transform dict into pd.df once in the beginning instead of in every function call in order to save computing cost\n",
    "critics = pd.DataFrame.from_dict(critics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#100k movie lense dataset\n",
    "\n",
    "headers = ['user id', 'item id', 'rating', 'timestamp'] \n",
    "rating_raw = pd.read_table(f'{data_path}/DataSets/extra/ml-100k/u.data', header=None, names=headers)\n",
    "rating_raw.drop(['timestamp'], axis=1, inplace=True)\n",
    "\n",
    "headers = ['movie id', 'movie title'] \n",
    "title = pd.read_table(f'{data_path}/DataSets/extra/ml-100k/u.item', encoding='latin-1', header=None, sep='|')\n",
    "title = title.iloc[:, :2]\n",
    "title.columns = ['MovieId', 'MovieTitle']\n",
    "title[\"Movie\"] = title['MovieId'].astype(str) + ': ' + title['MovieTitle']\n",
    "\n",
    "critics_100k = rating_raw.merge(title, how='left', left_on='item id', right_on='MovieId')\n",
    "\n",
    "critics_100k.drop(['item id', 'MovieId', 'MovieTitle'], axis=1, inplace=True)\n",
    "critics_100k['user id'].astype(str)\n",
    "\n",
    "critics_100k = critics_100k.pivot(index='Movie', columns='user id', values='rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the Pearson Correlation\n",
    "\n",
    "The following Cell computes the pearson Correlation of a given pair of Persons. The Correlation is hereby computed as a correlation dataframe using the .corr method included in Pandas. The pandas specific method is chosen over e.g. scipy.stats.pearsonr since it can handle the dataframe more efficiently for example in terms of NA values (The Pandas Method is overall a natural fit with Pandas Dataframes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "\n",
    "def pearsonMatrix(prefs):\n",
    "    \"\"\"\n",
    "    Computes the complete pearson correlation Matrix.\n",
    "    \"\"\"\n",
    "    matrix = prefs.corr(method='pearson') #.corr computes pearson correlation of all inputted pairs and outputs in matrix\n",
    "    return matrix #returns complete correlation matrix\n",
    "\n",
    "def pearsonSimilarity(person1, person2, corrM):\n",
    "    \"\"\"\n",
    "    Calls the desired pair of persons from the complete correlation Matrix.\n",
    "    \"\"\"\n",
    "    similarity = corrM.loc[person1, person2] #.loc calls the desired pair of persons from the complete correlation Matrix\n",
    "    return similarity #returns single correlation value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate Ratings and Extract Recommendations per User\n",
    "In the following Cell the missing ratings are estimated for a given User. \n",
    "\n",
    "As for loops are usually a highly inefficient way of working with table data I aimed to make as many computations as possible in dataframe/ vector format.\n",
    "\n",
    "In order to compute the V weights the complete correlation Matrix is passed to getRecommendations. I created a dictionary from the row of correlationts that represent the correlatin of all Vs with given U. This dictionary is then apended to the rating matrix as an additional row (index ='similarity_v').\n",
    "\n",
    "I was following the formula of personalized & normalized collaborative filtering (S = sum((r - mean(rV))* w) / sum(w)). Therefore, I firstly needed to compute the product of all of V's ratings subtracted by V's rating mean and the similarity between U and the respective V for every item that is to be estimated. The rating is normalized by adding the mean rating as a new row to the dataframe and subtracting it in the iteration over all the estimation targets. Since we included W as 'similarity_v' in the main dataframe this figure needs to be multiplied with each row (representing the ratings per movie) of movie ratings. To do this I iterate over the movies that need to be estimated (not rated by U so far) and use these as index for the respectve vector multiplication. The sum of each iteration is then divided by the sum of the entire 'similarity_v' (division done as part of iteration). For each iteration the resulting score is inserted in the main dataframe for U & the respective movie in order to save memory power (in comparison to save it in e.g. an extra list).\n",
    "\n",
    "The entire column U of the main matrix is then inputtet into a scaler (sklearn MinMaxScaler) in order to adapt tyhe estimations for the given 1-5 scale.\n",
    "\n",
    "The not rated movienames as well as the estimations are then written into the desired output format (list of tuples).\n",
    "In the final step this list is sorted (descending) and filtered for the top N results which represent the recommendations to U."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations(prefs,person, similarity_matrix):  \n",
    "    \"\"\"\n",
    "    Computing an estimation for the missing rating for a given User U.\n",
    "    \"\"\"\n",
    "    ## Appending Similarities (W) as weight row to main dataframe\n",
    "    similarity_dict = {} #define dict with similarities to person\n",
    "    for i in prefs.columns: similarity_dict[i] = similarity_matrix.loc[person, i] #append similarity of every user in main dataframe to dict\n",
    "    prefs = prefs.append(pd.Series(similarity_dict,name='similarity_v')) #appending similarities of V & U as new row to main dataframe   \n",
    "     \n",
    "    ## Compute mean movie rating given by V in order to normalise later\n",
    "    prefs.loc['mean_rating_v'] = prefs.mean(axis=0) #Compute V rating mean in new row\n",
    "    \n",
    "    ## Computing the sum of weights (Denominator in formula) \n",
    "    sum_of_v_weights = prefs.loc['similarity_v'].sum() #summing up the row entries in weight row\n",
    "        \n",
    "    ## Define list of movies that have not been rated by U and therefore need to be iterated\n",
    "    not_rated = prefs[person][prefs[person].isna()].index #extract list of movies not rated by U (need to be estimated)\n",
    "        \n",
    "    ## Iterate movie names that have not been rated by U\n",
    "    for m in not_rated: #for every movie that was not rated\n",
    "        prefs.loc['normalised_rating'] = prefs.loc[m, :].values - prefs.loc['mean_rating_v'].values #compute normalised rating\n",
    "        prefs.loc['weighted_rating'] = prefs.loc['normalised_rating'].values * prefs.loc['similarity_v', :].values #movie rating of V * Wvu (create new row / overwrite row with all results for movie m of iteration)           \n",
    "        prefs.loc[m, person] = np.nansum(prefs.loc['weighted_rating'].values) / sum_of_v_weights #U score estimation by summing all weithed ratings, dividing by sum of weights & inserting in respective plave in U column\n",
    "            \n",
    "    ## Scale Estimated Ratings on the given scale of 0-5\n",
    "    scaler = MinMaxScaler((0, 5)) #define scaler (sklearn package)\n",
    "    prefs[person] = scaler.fit_transform(prefs[[person]]) #insert U column (containing estimations into scaler)\n",
    "    \n",
    "    ## Write Results in output format (List of Tuples)\n",
    "    rankings = [] #define list to append tuples \n",
    "    for m in not_rated: rankings.append((prefs.loc[m, person], m)) #append estimated pair of movie name and estimated rating as tuple to list\n",
    "                \n",
    "    return sorted(rankings, reverse = True)[:10] #return sorted list of tuples (reverse = True for descending order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighbourhood Selection\n",
    "The following cell computes the neighbourhood to user U that can then be considered to compute recommendations more efficiently.\n",
    "\n",
    "##### Approach1:\n",
    "To do this the complete similarity matrix is passed to the function. Then I sorted the matrix by the index respective to the name of U (Equal to a ranking). From this ranking the number of desired neighbourhood members is extracted from the dataframe. Ultimately, the colums of the leftover rankings are called and filtered for the top N.\n",
    "\n",
    "##### Approach2:\n",
    "The second approach uses a given threshold in order to select the neighbourhood. This threshold was selected as > .5 and < .-5 correlation in this case. (default on False due to bad test results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topMatches(prefs, similarity_matrix, person,n=10,neighbourhood_size=20, threshold_option=False, threshold=.5):\n",
    "    \"\"\"\n",
    "    Computes neighbourhood of U that is inserted into getRecommendations & calls get Recommendations.\n",
    "    \"\"\"\n",
    "    #if function for optional threshold\n",
    "    if threshold_option == True:\n",
    "        #check similarity matrixa against threshold and selct index as neighbourhood\n",
    "        neighbourhood = similarity_matrix[abs(similarity_matrix.loc[person, :]) > threshold].index\n",
    "        \n",
    "        #define final dataframe with defined columns\n",
    "        final_ratings = prefs.loc[:, neighbourhood]  \n",
    "    \n",
    "    elif threshold_option == False:\n",
    "        #sorting values in the similarity matrix by row (axis 1) of respective person (ascending for ranking from high to low)\n",
    "        similarity_matrix.sort_values(axis=1, by=person, inplace=True, ascending=False)\n",
    " \n",
    "        #call columns of ranked neigbours(since U is also included)\n",
    "        neighbourhood = similarity_matrix.columns[:neighbourhood_size+1]\n",
    "        \n",
    "        #define the final dataframe as all the columns until neighbourhood_size \n",
    "        final_ratings = prefs.loc[:, neighbourhood]\n",
    " \n",
    "    return final_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it together and calling the functions\n",
    "The following cells defines a function that calls all the functions in the right order.\n",
    "The function needs the dataset as well as the \"mode\" as input.\n",
    "\n",
    "The function also measures the runtime in seconds. Final result for the sample dataset hereby 0.023 seconds and for the 100k dataset 3.208 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for Mock Dataset\n",
      "Recommendations for User 4489: Valery:\n",
      "[(3.4536672646823403, '780: Independence Day (ID4) (1996)'), (2.9366979049586686, '2916: Total Recall (1990)'), (1.6663555021333516, '34: Babe (1995)'), (0.0, '3578: Gladiator (2000)')]\n",
      "Running for 100k Dataset\n",
      "Recommendations for User 470:\n",
      "[(0.5931072832671631, '313: Titanic (1997)'), (0.5339781122946161, '333: Game, The (1997)'), (0.4677178978198913, '300: Air Force One (1997)'), (0.4498128249731095, '347: Wag the Dog (1997)'), (0.4363567112872689, '310: Rainmaker, The (1997)'), (0.4228478918151617, '332: Kiss the Girls (1997)'), (0.42239450943772927, '269: Full Monty, The (1997)'), (0.40805967233929913, '272: Good Will Hunting (1997)'), (0.3775855417754484, '350: Fallen (1998)'), (0.34137972832520513, '881: Money Talks (1997)')]\n"
     ]
    }
   ],
   "source": [
    "def run_recommender(prefs, mode):\n",
    "    #### Run with Mock Dataset ####\n",
    "    #start = time.perf_counter()\n",
    "    print(f'Running for {mode} Dataset')\n",
    "    \n",
    "    #randomply choose a user from the selected dataset to estimate ratings for\n",
    "    person_U = random.choice(prefs.columns)\n",
    "    \n",
    "    #compute complete correlation matrix\n",
    "    corrMatrix = pearsonMatrix(prefs)\n",
    "\n",
    "    #computing the neighbourhood of U\n",
    "    final_neigh_matrix = topMatches(prefs, person=person_U, similarity_matrix=corrMatrix)\n",
    "\n",
    "    #call getRecommendations function with neighbourhood dataframe\n",
    "    recommendations = getRecommendations(prefs=final_neigh_matrix, person=person_U, similarity_matrix=corrMatrix)\n",
    "\n",
    "    #print final results\n",
    "    print(f'Recommendations for User {person_U}:')\n",
    "    print(recommendations)\n",
    "\n",
    "    #end = time.perf_counter()\n",
    "    #print(f'Total Runtime: {end-start} seconds')\n",
    "    return\n",
    "\n",
    "run_recommender(critics, mode='Mock')\n",
    "run_recommender(critics_100k, mode='100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Critics Regression Comparison (Scatter Plot)\n",
    "The following cells firstly plot the movie ratings of two randomly chosen users from the database on a scatterplot. Secondly, the resulting scatterplot is validated computing the pearsonSimilarity between the users. As expected the result of the plot explains the pearsonCorrelation.\n",
    "\n",
    "The Scatterplot of two User's ratings represents the similarity between the two respective users.\n",
    "As more the regression of the pair is on one line in the plot as closer will be result of pearsonSimilarity be to 1 or - 1 (depending on the nature of the line). On the other side, as more clustered the regression is in the plot as closer will the regression be to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "corrMatrix = pearsonMatrix(critics_100k) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fae96e30f50>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "user1 = random.choice(critics_100k.columns) # choosing a random user 1 from the dataset\n",
    "user2 = random.choice(critics_100k.columns) # choosing a random user 1 from the dataset\n",
    "plt.plot(critics_100k[user1], critics_100k[user2], '.') #plotting the scatter of the rating of user1 & user2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40402651703136505"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonSimilarity(user1, user2, corrMatrix) #compute the pearson correlation of user1 & user2 movie ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
