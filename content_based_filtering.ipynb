{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based Recommender\n",
    "A content based recommender develops content recommendations based on a given item taxonomy and the respective user preferences usign this taxonomy. Therefore key questions that need to be answered are:<br>\n",
    "1. How to model Items\n",
    "2. How to model user preferences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Data Import ####\n",
    "a_votes = pd.read_csv(f'{data_path}/InputData/AnswerUpvotes.csv') # votes represent proactively signalled positive and negative interest in the question by the user\n",
    "q_feedback = pd.read_csv(f'{data_path}/InputData/QuestionsFeedback.csv') # Feedback to users on given answer based on up- and downvotes\n",
    "topics = pd.read_csv(f'{data_path}/InputData/TopicsXQuestions.csv') # taxonomy in form of topics and questions that are each assigned to the topics\n",
    "\n",
    "#since topic names will be encoded I created an item & taxonomy(topcic) dictionary to access the original names\n",
    "item_dict = {}\n",
    "for row in topics.iterrows(): item_dict[row[1][0]] = row[0]\n",
    "topic_dict ={}\n",
    "for count, topic in enumerate(topics.columns): topic_dict[topic]=count \n",
    "\n",
    "# droping question names since they are string\n",
    "a_votes.drop(['Unnamed: 0'], inplace=True,axis=1) \n",
    "q_feedback.drop(['Unnamed: 0'], inplace=True,axis=1)\n",
    "topics.drop(['Unnamed: 0'], inplace=True,axis=1)\n",
    "\n",
    "# replacing topic names with number for matrix multiplaction later\n",
    "a_votes.rename(columns=topic_dict, inplace=True)\n",
    "q_feedback.rename(columns=topic_dict, inplace=True)\n",
    "topics.rename(columns=topic_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling User Profiles\n",
    "The following cell models the user profiles as matrix product from taxonomy of the items and and given user preferences.<br>\n",
    "\n",
    "Firstly, I created a target dataframe. Secondly, I left the option open to run the function for Simple Unary, Unit Weight as well as TFIDF model. For the latter two the taxonomy weights of the items need to be adapted. This represents the uniqueness of the category (1/number of items in category).<br>\n",
    "\n",
    "Secondy, I iterated over the users in the database, replacing nans by 0, and finally again giving the choice between Simple Unary or Unit Weights or TFIDF. For the former two taxonomy and user user ratings can simply be multiplied in order to retrieve the respective user preference for each User. For the TFIDF model however, I initated the computation of IDF. After that the mutliplication of taxonomy and user ratings is processed and finally per category multiplied by the recpective IDF figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_pref(user_ratings, taxonomy, pref_mode='SimpleUnary'):\n",
    "    '''\n",
    "    Modelling user Profiles as Product of Items' taxonomy attribution and user taxonomy preferences.\n",
    "    '''\n",
    "    user_pref_df = pd.DataFrame(columns=user_ratings.columns, index=taxonomy.index) #creating result df\n",
    "    \n",
    "    if pref_mode == 'UnitWeights' or pref_mode == 'TFIDF': # If we are modelling Unit Weights or TFIDF  \n",
    "            taxonomy = taxonomy.div(taxonomy.sum(axis=1), axis=0) #Taxonomy per item needs to be aggregated - representing uniqueness of the taxonomy cateory\n",
    "    \n",
    "    for u in user_ratings.columns: #iterating all users in dataset     \n",
    "        \n",
    "        rated = user_ratings.loc[:, u].fillna(0).values #fill nan values with 0 instead (representing neutral rating)\n",
    "        \n",
    "        if pref_mode == 'SimpleUnary' or pref_mode == 'UnitWeights': #if simple or unit weights\n",
    "            user_pref_df[u] = np.dot(taxonomy.values, rated) # compute simple matrix multiplacation of taxonomy and ratings\n",
    "        \n",
    "        elif pref_mode == 'TFIDF': #if TFIDF \n",
    "            idf = np.log(len(taxonomy) / taxonomy.sum(axis=1)) #compute IDF\n",
    "            user_pref_df_vec = np.dot(taxonomy.values, rated) #multiply taxonomy and rating matrix\n",
    "            user_pref_df[u] = user_pref_df_vec * idf # multiply the result for each category by the respective IDF\n",
    "\n",
    "    return user_pref_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating User Profiles\n",
    "The following Cell calls the modelling function of the user profiles in a way that a dictionary is created containign all the necessary user profiles, for all the desired model types. Based on this we can keep the algorithm lean and neat.<br>\n",
    "\n",
    "Hereby, it creates profiles for all users based on the three model types (Simple Unary, Unit Weights and TFDIF). Furthermore all available types of user feedback (feedback, votes and both combined). Feedback represents the feeback that each individual user has given per question (up or down vote). That given clearly indicates interest or missing interest. Votes represent the upvotes and downvotes that users have received for the answers they have given to others questions. This information is hereby used as a \"repuation\" score for the topic. The combined profiles combine the standardized values of interest and reputation by adding the values up and again standadizing the result. <br>\n",
    "\n",
    "The standadization is necessary since for the combined profiles we assume that interest and reputation are equally important (Depending on the use case of the recommender). For example do we intent using the recommender in order to recommend questions to give anserws, targeting active users it might make sense to weight the reputation higher. For users that tend to read but not answer we should do the opposite. The standardization is necessary to weigh the different scales of rating and evaluation equally. Concerning the standadization another tradeoff was necessary between standardizing across all users or per user. Here I chose to standadize per user, not to falsely compare different rating scales (these are normalized later in the recommendation function).<br>\n",
    "\n",
    "Furthermore, I am computing the mean profile for each profile type computed (represented by the mean relevance for users per topic). The mean is later used in order solve the cold start problem by combining personalized with unpersonalized content based recommendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "def stand(df): \n",
    "    \"\"\"\n",
    "    Standardizing a given array.\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        array = df.loc[:, col].values\n",
    "        df[col] = (array - np.mean(array)) / np.std(array)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Computing user profiles and creating a profiles dict to index them. (profiles for all model and profiles types)\n",
    "\"\"\"\n",
    "iteration_dict = {'interest': q_feedback, 'reputation': a_votes}\n",
    "model_types = ['SimpleUnary', 'UnitWeights', 'TFIDF']\n",
    "profiles_dict = {}\n",
    "\n",
    "for model in model_types: #iterate all model types\n",
    "    for i in iteration_dict: #iterate all profile types\n",
    "        profiles_dict[f'{i}_{model}'] = user_pref(iteration_dict[i], topics.transpose(), pref_mode=model) #insert every combination of desired models\n",
    "        profiles_dict[f'{i}_{model}']['mean_profile'] = profiles_dict[f'{i}_{model}'].mean(axis=1) #insert mean profile for every combination of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Computing the combined profiles per model type and adding them to the profile dict.\n",
    "\"\"\"\n",
    "for model in model_types:\n",
    "    profiles_dict[f'combined_profile_{model}'] = stand(stand(profiles_dict[f'interest_{model}']) + stand(profiles_dict[f'interest_{model}']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Recommendations\n",
    "The following two Cells compute the relevance of each question for each user according to the defined models. The reults are fitted into a dict of arrays. Each of the arrays represent the question relevance for each question for one user.<br>\n",
    "\n",
    "To do this, I am firstly iterating all model types in order to call all user types per model type. The model type is hereby defined outside of this function in the final function call. Therefore this function solely passes on the attained model type.<br>\n",
    "\n",
    "Before the chosen profiles and the taxonomy are finally combined in a matrix multiplication I made use of an if statement in order to incorporate the possibility of activating a hybrid recommendation approach. Therefore, the if statement checks whether the profiles have preferences defined. Should this not be the case the mean value for the respective model type is used and passed on into the matrix multiplication.<br>\n",
    "\n",
    "As mentioned above result of this function is a dict indexing the relevance of each question for each user. This relevance is represented by the cosine distance between the user profile and the question in the multi-dimensional model space. Therefore, the value for each question lies between -1 and 1. The values between -1 and 0 are hereby interpreted as dislike probability while the values between 0 and 1 are interpreted as like probability. 0 is interpreted as neutral.\n",
    "#### Possbile Customization Choices:\n",
    "profile_type: interest, reputation, combined_profiles<br>\n",
    "model_type: SimpleUnary, UnitWeights, TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_relevance(taxonomy, profile_type, switched_hybrid, model_types=model_types, profiles_dict=profiles_dict):\n",
    "    \"\"\"\n",
    "    Computing the relevance score for each question and profile. (multiplying profiles and taxonomy)\n",
    "    \"\"\"\n",
    "    relevance_d = {} #defining the output dict\n",
    "    for model in model_types: #iterate all model types\n",
    "        u_profiles = profiles_dict[f'{profile_type}_{model}']\n",
    "                \n",
    "        for u in u_profiles.columns: #iterating all user profiles\n",
    "            df = u_profiles[u].values # 1st component of multiplocation (profiles/preferences)\n",
    "            s = taxonomy.values  #2nd component of multiplication (taxonomy)\n",
    "   \n",
    "            if switched_hybrid=='YES' and u_profiles[u].isnull().values.all(axis=0): #if statement to check if values are NAN \n",
    "                df = u_profiles['mean_profile'].values #-> if yes choose mean profile in order to compute unpersonalized recommendation\n",
    "                    \n",
    "            relevance_d[f'{u}_{model}'] = np.cos(np.dot(s, df)) #index the result as cosine of the mutliplication result\n",
    "    return relevance_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Cell interprets the question relevance per user that has been computed earlier. It therefore rounds the estimations and translates every estimation < -.5 as dislike prediction, > .5 as like prediction and everything in between as neutral prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(user, model, profile_type, switched_hybrid):\n",
    "    \"\"\"\n",
    "    Interpreting the estimated relevance scores into real life relevant actions (probability of Like, Dislike & Neutral)\n",
    "    \"\"\"\n",
    "    predictions_v = q_relevance(topics, profile_type=profile_type, switched_hybrid=switched_hybrid)[f'{user}_{model}'] #calling the relevance function\n",
    "    predictions_df = pd.DataFrame(predictions_v, index=item_dict.keys(), columns=[user]) #create df as destination of the preditcions\n",
    "    \n",
    "    predictions_df['like_est'] = round(predictions_df[user]) #rounding the value in order to have a clear action\n",
    "    predictions_df.loc[predictions_df['like_est'] == -1, 'like_est'] = 'DISLIKE' #dislike when prediction < -.5\n",
    "    predictions_df.loc[predictions_df['like_est'] == 0, 'like_est'] = 'NEUTRAL' #neutral when -.5 < estimation <.5\n",
    "    predictions_df.loc[predictions_df['like_est'] == 1, 'like_est'] = 'LIKE' #like when estimation > .5\n",
    "    \n",
    "    return predictions_df.sort_values(by=user, axis=0, ascending=False) #return sorted version of the outpur dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Recommendation Engine\n",
    "The following function runs the recommendation engine by taking the desired model, profile type as well as an indication wheather the hybrid recommendation should be activated or not as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_recommender(model, profile_type, switched_hybrid):\n",
    "    \"\"\"\n",
    "    Running the recommender workflow & printing the evaluation of the results.\n",
    "    \"\"\"\n",
    "    users_l = ['User 1', 'User 2', 'User 3', 'User 4'] #defining a list of users to iterate\n",
    "    results_df = pd.DataFrame(index=item_dict.keys()) #defining a result df\n",
    "\n",
    "    for user in users_l: #iterating the defined users\n",
    "        pred_df = predictions(user=user, model=model, profile_type=profile_type, switched_hybrid=switched_hybrid) #calling the prediction function per user\n",
    "        results_df[user] = pred_df[user] #appending results to result df for processing\n",
    "        results_df[f'{user}_result'] = pred_df['like_est'] #appending results to result df for processing\n",
    "        \n",
    "        like_count = len(results_df.loc[results_df[f'{user}_result'] == 'LIKE']) #interpret estimated figures for LIKES\n",
    "        dislike_count = len(results_df.loc[results_df[f'{user}_result'] == 'DISLIKE']) #interpret estimated figures for DISLIKES\n",
    "        neutral_count = len(results_df.loc[results_df[f'{user}_result'] == 'NEUTRAL']) #interpret estimated figures for NEUTRALS\n",
    "\n",
    "        ##print recommended results per user\n",
    "        print(f'####---------{user}---------####')\n",
    "        print(f'Number of Likes: {like_count}')\n",
    "        print(f'Number of Neutral: {dislike_count}')\n",
    "        print(f'Number of Dislikes: {neutral_count}')\n",
    "        \n",
    "        #if no estimations dont print top questions (cold start problem)\n",
    "        if pred_df[user].isnull().values.all(axis=0) ==False:\n",
    "            print(f'##---Top 5 Questions---##')\n",
    "            print(pred_df[user].sort_values(axis=0, ascending=False).index.values[:5])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1: Simple Unary Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####---------User 1---------####\n",
      "Number of Likes: 6\n",
      "Number of Neutral: 8\n",
      "Number of Dislikes: 6\n",
      "##---Top 5 Questions---##\n",
      "['question11' 'question15' 'question18' 'question7' 'question5']\n",
      "####---------User 2---------####\n",
      "Number of Likes: 7\n",
      "Number of Neutral: 6\n",
      "Number of Dislikes: 7\n",
      "##---Top 5 Questions---##\n",
      "['question19' 'question11' 'question5' 'question6' 'question10']\n",
      "####---------User 3---------####\n",
      "Number of Likes: 6\n",
      "Number of Neutral: 7\n",
      "Number of Dislikes: 7\n",
      "##---Top 5 Questions---##\n",
      "['question4' 'question7' 'question1' 'question18' 'question6']\n",
      "####---------User 4---------####\n",
      "Number of Likes: 0\n",
      "Number of Neutral: 0\n",
      "Number of Dislikes: 0\n"
     ]
    }
   ],
   "source": [
    "run_recommender(model='SimpleUnary', profile_type='interest', switched_hybrid='NO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2: Unit Weight Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####---------User 1---------####\n",
      "Number of Likes: 6\n",
      "Number of Neutral: 8\n",
      "Number of Dislikes: 6\n",
      "##---Top 5 Questions---##\n",
      "['question18' 'question11' 'question15' 'question3' 'question7']\n",
      "####---------User 2---------####\n",
      "Number of Likes: 9\n",
      "Number of Neutral: 6\n",
      "Number of Dislikes: 5\n",
      "##---Top 5 Questions---##\n",
      "['question11' 'question5' 'question19' 'question10' 'question8']\n",
      "####---------User 3---------####\n",
      "Number of Likes: 6\n",
      "Number of Neutral: 7\n",
      "Number of Dislikes: 7\n",
      "##---Top 5 Questions---##\n",
      "['question4' 'question7' 'question13' 'question1' 'question3']\n",
      "####---------User 4---------####\n",
      "Number of Likes: 0\n",
      "Number of Neutral: 0\n",
      "Number of Dislikes: 0\n"
     ]
    }
   ],
   "source": [
    "run_recommender('UnitWeights', profile_type='interest', switched_hybrid='NO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3: TFIDF Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####---------User 1---------####\n",
      "Number of Likes: 6\n",
      "Number of Neutral: 8\n",
      "Number of Dislikes: 6\n",
      "##---Top 5 Questions---##\n",
      "['question18' 'question11' 'question15' 'question3' 'question7']\n",
      "####---------User 2---------####\n",
      "Number of Likes: 9\n",
      "Number of Neutral: 6\n",
      "Number of Dislikes: 5\n",
      "##---Top 5 Questions---##\n",
      "['question11' 'question5' 'question19' 'question10' 'question8']\n",
      "####---------User 3---------####\n",
      "Number of Likes: 6\n",
      "Number of Neutral: 7\n",
      "Number of Dislikes: 7\n",
      "##---Top 5 Questions---##\n",
      "['question4' 'question7' 'question13' 'question1' 'question3']\n",
      "####---------User 4---------####\n",
      "Number of Likes: 0\n",
      "Number of Neutral: 0\n",
      "Number of Dislikes: 0\n"
     ]
    }
   ],
   "source": [
    "run_recommender('TFIDF', profile_type='interest', switched_hybrid='NO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4: Synthetic Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####---------User 1---------####\n",
      "Number of Likes: 6\n",
      "Number of Neutral: 8\n",
      "Number of Dislikes: 6\n",
      "##---Top 5 Questions---##\n",
      "['question18' 'question11' 'question15' 'question3' 'question7']\n",
      "####---------User 2---------####\n",
      "Number of Likes: 9\n",
      "Number of Neutral: 6\n",
      "Number of Dislikes: 5\n",
      "##---Top 5 Questions---##\n",
      "['question11' 'question5' 'question19' 'question10' 'question8']\n",
      "####---------User 3---------####\n",
      "Number of Likes: 6\n",
      "Number of Neutral: 7\n",
      "Number of Dislikes: 7\n",
      "##---Top 5 Questions---##\n",
      "['question4' 'question7' 'question13' 'question1' 'question3']\n",
      "####---------User 4---------####\n",
      "Number of Likes: 4\n",
      "Number of Neutral: 6\n",
      "Number of Dislikes: 10\n",
      "##---Top 5 Questions---##\n",
      "['question7' 'question6' 'question19' 'question10' 'question3']\n"
     ]
    }
   ],
   "source": [
    "run_recommender('TFIDF', profile_type='interest', switched_hybrid='YES')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 5: Trust Aware Collaborative Filtering\n",
    "For the final part of the practice I firstly thought about developing a trust aware user-user collaborative filtering model. However, the first testing showed that the limited ammount of data is clearly not enough to work out sufficient similarities between the users. The following cell demontrates the correlation matrix between the given user dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%timeit\n",
    "def pearsonMatrix(prefs):\n",
    "    \"\"\"\n",
    "    Computes the complete pearson correlation Matrix.\n",
    "    \"\"\"\n",
    "    matrix = prefs.corr(method='pearson') #.corr computes pearson correlation of all inputted pairs and outputs in matrix\n",
    "    return matrix #returns complete correlation matrix\n",
    "\n",
    "def pearsonSimilarity(person1, person2, corrM):\n",
    "    \"\"\"\n",
    "    Calls the desired pair of persons from the complete correlation Matrix.\n",
    "    \"\"\"\n",
    "    similarity = corrM.loc[person1, person2] #.loc calls the desired pair of persons from the complete correlation Matrix\n",
    "    return similarity #returns single correlation value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User 1</th>\n",
       "      <th>User 2</th>\n",
       "      <th>User 3</th>\n",
       "      <th>User 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User 1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.414141</td>\n",
       "      <td>-0.167968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 2</th>\n",
       "      <td>-0.414141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.205294</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 3</th>\n",
       "      <td>-0.167968</td>\n",
       "      <td>0.205294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User 4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          User 1    User 2    User 3  User 4\n",
       "User 1  1.000000 -0.414141 -0.167968     NaN\n",
       "User 2 -0.414141  1.000000  0.205294     NaN\n",
       "User 3 -0.167968  0.205294  1.000000     NaN\n",
       "User 4       NaN       NaN       NaN     NaN"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonMatrix(q_feedback.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the Matrix is way too limited and next to its small size also does not show any significant similarities I decided to change my approach and shift to a trust aware item-item collaborative filtering model. The following cell displays the first 5 rows of the respective correlation matrix. The quality difference is clearly significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.816497</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.816497</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1   2         3         4         5         6         7   \\\n",
       "0  1.000000 -1.000000 NaN -0.816497  0.000000  0.816497  0.000000  0.000000   \n",
       "1 -1.000000  1.000000 NaN  0.816497  0.000000 -0.816497  0.000000  0.000000   \n",
       "2       NaN       NaN NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3 -0.816497  0.816497 NaN  1.000000 -0.333333 -0.333333  0.333333 -0.333333   \n",
       "4  0.000000  0.000000 NaN -0.333333  1.000000 -0.333333 -1.000000  1.000000   \n",
       "\n",
       "   8   9   10        11  12  13        14        15        16  17        18  \\\n",
       "0 NaN NaN NaN  0.707107 NaN NaN  0.000000  0.500000 -0.816497 NaN -0.816497   \n",
       "1 NaN NaN NaN -0.707107 NaN NaN  0.000000 -0.500000  0.816497 NaN  0.816497   \n",
       "2 NaN NaN NaN       NaN NaN NaN       NaN       NaN       NaN NaN       NaN   \n",
       "3 NaN NaN NaN -0.577350 NaN NaN  0.333333  0.000000  1.000000 NaN  0.333333   \n",
       "4 NaN NaN NaN -0.577350 NaN NaN -1.000000 -0.816497 -0.333333 NaN  0.333333   \n",
       "\n",
       "   19  \n",
       "0 NaN  \n",
       "1 NaN  \n",
       "2 NaN  \n",
       "3 NaN  \n",
       "4 NaN  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonMatrix(q_feedback.transpose().fillna(0)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is the intention to develop a trust aware recommender system it is crucial to determine initially, how the trust in a platform's user can be determined and where it can best be inserted into the estimation formula. In this case I decided to use the up-and downvotes that have been submitted for the answers that our users posted. These represent the expertise and quality of interaction with the quora platorm.<br>\n",
    "\n",
    "In order to get started the reputation values therefore first need to be computed per user. In this case the reputation is computed per user and across taxonomy topics. This is relevant as applying the reputation per taxonomy category might lead to even better recommendations.<br>\n",
    "\n",
    "The reputation needs to elevate or weaken the rating given by the user. Therefore the mean number of up/downvotes is simply multiplied by the interest matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a reputation dict ## \n",
    "reputation_dict = {}\n",
    "for count, user in enumerate(a_votes.columns): #iterate all users in the dataset\n",
    "    reputation_dict[user] = a_votes.mean(axis=0)[count] #for every user the reputation = mean of up&downvotes on answers submitted by the same user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the Input Matrix for the recommender ## \n",
    "trust_aware_rating = q_feedback * np.array(list(reputation_dict.values())) # Incorporate the reputaiton in the ratings\n",
    "input_m = trust_aware_rating.transpose().fillna(0) #transpose the matrix in order to focus on item-item similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrM = pearsonMatrix(input_m) #define correlation matrix between questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function in the following cell computes the actual relevance scores for each items and one given user. Hereby the solution is trust aware, as the input matrix of the weightings has been multiplied with the reputation scores per user. Therefore the ratings of more trustworthy users count more in the consideration of the individual votes as well as the average. (Numerator of the score estimation formula)<br>\n",
    "\n",
    "The if statement checks for users that have not given any ratings yet and therefore identifies cases of the cold start problem. In this case the function replaces the user ratings with the mean user rating that has been given by all the other users in the database. We therefore assume that the best recommendation for a user that we dont know at all is the average recommendation we give to all our other users. The average recommendation is hereby also trust-aware!<br>\n",
    "\n",
    "Since we are talking about probabilities of liking and diskliking a certain item the computed values need to be normalized between -1 & 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRecommendations(prefs,person, similarity_matrix):  \n",
    "    \"\"\"\n",
    "    Compute relevance score per item for a given user. \n",
    "    \"\"\"\n",
    "    ## Compute mean movie rating given by V in order to normalise later\n",
    "    prefs.loc['mean_rating_j'] = prefs.mean(axis=0) #Compute j rating mean in new row\n",
    "    \n",
    "    #incorporate usage of non-personalized recommendation for the cold-start problem\n",
    "    if np.count_nonzero(prefs.loc[person]) == 0 : #if statement to check if values are all 0 (representing no rating given = cold start) \n",
    "        prefs.loc[person] = prefs.loc['mean_rating_j'].values # if yes choose mean item rating in order to compute unpersonalized recommendat\n",
    "\n",
    "    results = []\n",
    "    for q in prefs.columns: #iterate all items in the database\n",
    "        prefs.loc['similarity_j'] = similarity_matrix.loc[q, :] #append the item-item similarity of the given item\n",
    "        sum_of_j_weights = prefs.loc['similarity_j'].sum() # sum the similarity weights between items\n",
    "        if sum_of_j_weights == 0: sum_of_j_weights = 1 #if all the similarity weights balance each other assume 1\n",
    "        \n",
    "        prefs.loc['normalised_rating'] = prefs.loc[person, :].values - prefs.loc['mean_rating_j'].values #normalise the rating by substracting the mean rating for the item\n",
    "        prefs.loc['weighted_rating'] = prefs.loc['normalised_rating'].values * prefs.loc['similarity_j', :].values #item rating of j * Wij (create new row / overwrite row with all results for item in current   iteration)           \n",
    "        \n",
    "        results.append(np.nansum(prefs.loc['weighted_rating'].values) / sum_of_j_weights) #compute relevance score by dividing the components and append result to goven result list \n",
    "    \n",
    "    scaler = MinMaxScaler((-1, 1)) #define scaler (sklearn package)\n",
    "    results = scaler.fit_transform(np.array(results).reshape(-1, 1)) #insert U column (containing estimations into scaler)\n",
    "        \n",
    "    result_df = pd.DataFrame(columns=[person], index=prefs.columns) #define result df to pass to interpretation function\n",
    "    result_df[person] = results #append estimated score to result df to pass on to interpretation\n",
    "    \n",
    "    return result_df.round(0) #return sorted list of tuples (reverse = True for descending order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(user):\n",
    "    \"\"\"\n",
    "    Interpret the relevance ratings per item and make final predictions on that basis. (like, neutral, dislike for question domain)\n",
    "    \"\"\"\n",
    "    predictions_df = getRecommendations(input_m,user, similarity_matrix=corrM) #call recommendation function\n",
    "    predictions_df['like_est'] = round(predictions_df[user]) #round values to 0, 1, -1\n",
    "    predictions_df.loc[predictions_df['like_est'] == -1, 'like_est'] = 'DISLIKE' #dislike when prediction < -.5\n",
    "    predictions_df.loc[predictions_df['like_est'] == 0, 'like_est'] = 'NEUTRAL' #neutral when -.5 < estimation <.5\n",
    "    predictions_df.loc[predictions_df['like_est'] == 1, 'like_est'] = 'LIKE' #like when estimation > .5\n",
    "    \n",
    "    return predictions_df.sort_values(by=user, axis=0, ascending=False) #return sorted version of the outpur dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_recommender():\n",
    "    \"\"\"\n",
    "    Run the recommender and print results.\n",
    "    \"\"\"\n",
    "    users_l = ['User 1', 'User 2', 'User 3', 'User 4'] #specify the users that are to be iterated\n",
    "\n",
    "    for user in users_l: #iterate the specified users\n",
    "        pred_df = predictions(user=user) #extract prediction figures\n",
    "        pred_df.rename({'like_est': f'{user}_result'}, axis=1, inplace=True) #rename column to specify for user\n",
    "        \n",
    "        like_count = len(pred_df.loc[pred_df[f'{user}_result'] == 'LIKE']) #interpret estimated figures for LIKES\n",
    "        dislike_count = len(pred_df.loc[pred_df[f'{user}_result'] == 'DISLIKE']) #interpret estimated figures for DISLIKES\n",
    "        neutral_count = len(pred_df.loc[pred_df[f'{user}_result'] == 'NEUTRAL']) #interpret estimated figures for NEUTRALS\n",
    "            \n",
    "        ##print recommended results per user\n",
    "        print(f'####---------{user}---------####')\n",
    "        print(f'Number of Likes: {like_count}')\n",
    "        print(f'Number of Neutral: {dislike_count}')\n",
    "        print(f'Number of Dislikes: {neutral_count}')\n",
    "        \n",
    "        #if no estimations dont print top questions (cold start problem)\n",
    "        if pred_df[user].isnull().values.all(axis=0) ==False:\n",
    "            print(f'##---Top 5 Questions---##')\n",
    "            print(pred_df[user].sort_values(axis=0, ascending=False).index.values[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####---------User 1---------####\n",
      "Number of Likes: 6\n",
      "Number of Neutral: 10\n",
      "Number of Dislikes: 4\n",
      "##---Top 5 Questions---##\n",
      "[ 4  6  7 15 11]\n",
      "####---------User 2---------####\n",
      "Number of Likes: 5\n",
      "Number of Neutral: 4\n",
      "Number of Dislikes: 11\n",
      "##---Top 5 Questions---##\n",
      "[11  4 14  6  7]\n",
      "####---------User 3---------####\n",
      "Number of Likes: 10\n",
      "Number of Neutral: 6\n",
      "Number of Dislikes: 4\n",
      "##---Top 5 Questions---##\n",
      "[ 2  3  8 17 16]\n",
      "####---------User 4---------####\n",
      "Number of Likes: 0\n",
      "Number of Neutral: 20\n",
      "Number of Dislikes: 0\n",
      "##---Top 5 Questions---##\n",
      "[19  2  1 18 17]\n"
     ]
    }
   ],
   "source": [
    "run_recommender()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
